# Multilingual and Cross-Lingual Intent Detection from Spoken Data using Whisper on the MINDS-14 Dataset
Semester project for the IFT-7030 Machine Learning for Signal Processing course at Université Laval

*Abstract*

This study presents an innovative approach to multi-
lingual and cross-lingual intent detection from spoken data, lever-
aging the cutting-edge capabilities of OpenAI’s Whisper model
on the MINDS-14 dataset. Our integrated pipeline architecture
combines automatic speech recognition (ASR), translation, and
intent classification models to process and understand raw speech
data across multiple languages. The Whisper model, renowned
for its proficiency in diverse linguistic and acoustic environments,
serves as the backbone for ASR. Subsequent translation to
English is performed using MarianMT, ensuring consistency in
language input for intent classification. The final stage employs
JointBERT for precise intent detection. The system’s perfor-
mance is rigorously evaluated using standard metrics such as
Word Error Rate (WER), BLEU, and ROUGE, alongside intent
classification accuracy. Our methodology demonstrates robust-
ness and high accuracy, making significant strides towards more
intuitive human-computer interaction in multilingual settings
